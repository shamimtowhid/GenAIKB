{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d23cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Synthetic data generation using Great for CICIDS training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ef8a436-113e-44e1-96e3-5df5990f0c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sharedrive/Nasik/LLM_3.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/home/sharedrive/Nasik/LLM_3.9/lib/python3.9/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 12:53, Epoch 200/200]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.890200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.697200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.605800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.536900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.496300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.476500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1033it [00:35, 29.42it/s]                                                                                                                \n",
      "/home/sharedrive/Nasik/LLM_3.9/lib/python3.9/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6600' max='6600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6600/6600 29:58, Epoch 200/200]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.717400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.651900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.604700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.557900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.517400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.484200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.457900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.437900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.422500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.411700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.403800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.397900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.395200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1012it [00:25, 39.36it/s]                                                                                                                \n",
      "/home/sharedrive/Nasik/LLM_3.9/lib/python3.9/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:36, Epoch 200/200]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1014it [00:26, 39.00it/s]                                                                                                                \n",
      "/home/sharedrive/Nasik/LLM_3.9/lib/python3.9/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:50, Epoch 200/200]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1033it [00:30, 33.50it/s]                                                                                                                \n",
      "/home/sharedrive/Nasik/LLM_3.9/lib/python3.9/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:25, Epoch 200/200]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1076it [00:32, 32.77it/s]                                                                                                                \n",
      "/home/sharedrive/Nasik/LLM_3.9/lib/python3.9/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8600' max='8600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8600/8600 38:34, Epoch 200/200]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.715100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.613800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.571100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.530600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.490700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.459400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.433600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.413200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.398100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.385700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.376500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.369200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.362900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.358900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.355600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.353000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.351600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1010it [00:23, 42.30it/s]                                                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Flow_Duration  Total_Length_of_Bwd_Packets  Bwd_Packet_Length_Max  \\\n",
      "0      5907512.0                          0.0                    0.0   \n",
      "1      5185197.0                          0.0                    0.0   \n",
      "2      5446804.0                          0.0                    0.0   \n",
      "3      5754952.0                          0.0                    0.0   \n",
      "4        72994.0                        134.0                  128.0   \n",
      "\n",
      "   Bwd_Packet_Length_Mean  Flow_Bytes/s  Flow_Packets/s  Flow_IAT_Std  \\\n",
      "0                0.000000      0.000000        0.677104  3.409869e+06   \n",
      "1                0.000000      0.000000        0.771427  2.992884e+06   \n",
      "2                0.000000      0.000000        0.734376  3.143948e+06   \n",
      "3                0.000000      0.000000        0.695054  3.321858e+06   \n",
      "4               44.666667   4685.316601       95.898293  2.885074e+04   \n",
      "\n",
      "   Flow_IAT_Max  Flow_IAT_Min  Fwd_IAT_Total  ...  Fwd_Packets/s  \\\n",
      "0     5906548.0         211.0      5907512.0  ...       0.507828   \n",
      "1     5184284.0         159.0      5185197.0  ...       0.578570   \n",
      "2     5445920.0         158.0      5446804.0  ...       0.550782   \n",
      "3     5754068.0         162.0      5754952.0  ...       0.521290   \n",
      "4       71054.0          57.0        72994.0  ...      54.799025   \n",
      "\n",
      "   Bwd_Packets/s  Max_Packet_Length  Packet_Length_Mean  Average_Packet_Size  \\\n",
      "0       0.169276                0.0                0.00             0.000000   \n",
      "1       0.192857                0.0                0.00             0.000000   \n",
      "2       0.183594                0.0                0.00             0.000000   \n",
      "3       0.173763                0.0                0.00             0.000000   \n",
      "4      41.099268              196.0               42.75            48.857143   \n",
      "\n",
      "   Avg_Bwd_Segment_Size  Subflow_Bwd_Bytes  min_seg_size_forward  \\\n",
      "0              0.000000                0.0                  32.0   \n",
      "1              0.000000                0.0                  32.0   \n",
      "2              0.000000                0.0                  32.0   \n",
      "3              0.000000                0.0                  32.0   \n",
      "4             44.666667              134.0                  20.0   \n",
      "\n",
      "                     Label  Data_Type  \n",
      "0  Web_Attack__Brute_Force   Original  \n",
      "1  Web_Attack__Brute_Force   Original  \n",
      "2          Web_Attack__XSS   Original  \n",
      "3          Web_Attack__XSS   Original  \n",
      "4                      Bot   Original  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from be_great import GReaT\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Disable tokenizer parallelism warning\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 4200\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Load the dataset\n",
    "train_df = pd.read_csv(\"./Data/CICIDS_data/CICIDS_clean_train.csv\")\n",
    "\n",
    "def change(df):\n",
    "    # Standardize column names\n",
    "    column_names = [name.strip().replace(\" \", \"_\") for name in df.columns]\n",
    "    _dict = {k: v for k, v in zip(df.columns, column_names)}\n",
    "    df.rename(columns=_dict, inplace=True)\n",
    "\n",
    "    # Standardize labels\n",
    "    labels = df[\"Label\"].unique().tolist()\n",
    "    new_labels = [''.join(filter(lambda x: ord(x) < 128, l.strip().replace(\" \", \"_\"))) for l in labels]\n",
    "    _dict = {k: v for k, v in zip(labels, new_labels)}\n",
    "    df[\"Label\"] = df[\"Label\"].replace(to_replace=_dict)\n",
    "    return df\n",
    "\n",
    "train_df = change(train_df)\n",
    "\n",
    "# Features to be used\n",
    "rf_features = ['Flow_Duration', 'Total_Length_of_Bwd_Packets', 'Bwd_Packet_Length_Max',\n",
    "       'Bwd_Packet_Length_Mean', 'Flow_Bytes/s', 'Flow_Packets/s',\n",
    "       'Flow_IAT_Std', 'Flow_IAT_Max', 'Flow_IAT_Min',\n",
    "       'Fwd_IAT_Total', 'Fwd_IAT_Mean', 'Fwd_IAT_Std', 'Fwd_IAT_Max',\n",
    "       'Fwd_IAT_Min', 'Fwd_Packets/s', 'Bwd_Packets/s', 'Max_Packet_Length',\n",
    "       'Packet_Length_Mean', 'Average_Packet_Size', 'Avg_Bwd_Segment_Size',\n",
    "       'Subflow_Bwd_Bytes', 'min_seg_size_forward']\n",
    "\n",
    "# Small classes for synthetic data generation\n",
    "small_classes = ['Web_Attack__XSS', 'Web_Attack__Brute_Force', 'Web_Attack__Sql_Injection', \n",
    "                 'Infiltration', 'Heartbleed', 'Bot']\n",
    "\n",
    "# Filter data for selected classes\n",
    "filtered_data = train_df[train_df['Label'].isin(small_classes)][rf_features + ['Label']]\n",
    "\n",
    "# DataFrame to store synthetic data\n",
    "synthetic_data_all = pd.DataFrame()\n",
    "\n",
    "# Initialize GReaT with a random seed\n",
    "model = GReaT(llm='distilgpt2', batch_size=32, epochs=200, fp16=True, seed=SEED)\n",
    "\n",
    "# Generate synthetic data for each class\n",
    "for label in small_classes:\n",
    "    class_data = filtered_data[filtered_data['Label'] == label][rf_features]\n",
    "    model.fit(class_data)\n",
    "    synthetic_class_data = model.sample(n_samples=1000, max_length=2000)  # Adjusted `max_length` for realistic sampling\n",
    "    synthetic_class_data['Label'] = label\n",
    "    synthetic_data_all = pd.concat([synthetic_data_all, synthetic_class_data], ignore_index=True)\n",
    "\n",
    "# Label data as original or synthetic\n",
    "filtered_data['Data_Type'] = 'Original'\n",
    "synthetic_data_all['Data_Type'] = 'Synthetic'\n",
    "\n",
    "# Combine original and synthetic data\n",
    "combined_data = pd.concat([filtered_data, synthetic_data_all], ignore_index=True)\n",
    "\n",
    "# Save combined data to a CSV file\n",
    "combined_data.to_csv(\"./Data/CICIDS_data/Great_Synthetic_1000_R3.csv\", index=False)\n",
    "\n",
    "# Display the first few rows of the combined dataset\n",
    "print(combined_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41881b0a-e1d0-4b9d-80f3-cb7d5d531df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e649c46-9d0e-4750-8ddb-53cba93ea6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1c427b-16a4-46c0-bb36-b0122d92cb53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24954bc-f353-4bce-9a05-26d3be56b724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df11ff1-b435-4209-9268-cf3c35fc3164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eca4c67-9f8e-4f9b-a157-e9abf82028d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Synthetic data generation on CICIDS Training dataset using the knowledge-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6b343b0-af48-43e6-a4d7-1a041fd33d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sharedrive/Nasik/LLM_3.9/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 227\n",
      "After: 217\n",
      "Before: 337\n",
      "After: 242\n",
      "Before: 14\n",
      "After: 12\n",
      "Before: 13\n",
      "After: 13\n",
      "Before: 1\n",
      "After: 1\n",
      "Before: 649\n",
      "After: 131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sharedrive/Nasik/LLM_3.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/home/sharedrive/Nasik/LLM_3.9/lib/python3.9/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:27, Epoch 1000/1000]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.456900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.229600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                 | 0/1000 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "1004it [03:58,  4.21it/s]                                                                                                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "Data Dropped: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:05,  5.59it/s]                                                                                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "Data Dropped: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sharedrive/Nasik/LLM_3.9/lib/python3.9/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15000' max='15000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15000/15000 1:04:49, Epoch 1000/1000]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.772400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.642200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.514300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.421700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.368300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.337100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.316400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.300100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.287400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.276500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.267600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.260800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.255300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.250600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.246800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.243200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.240400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.238200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.235900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.233900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.232100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.231400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.230400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.229500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.228400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.227200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.226600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.226300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.225700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1003it [00:26, 38.46it/s]                                                                                                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "Data Dropped: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "92it [00:02, 38.60it/s]                                                                                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Data Dropped: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sharedrive/Nasik/LLM_3.9/lib/python3.9/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33000' max='33000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33000/33000 2:31:42, Epoch 1000/1000]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.679600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.592200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.526400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.455900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.398800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.359000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.332000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.313100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.299700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.288400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.279900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.272300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.266300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.261500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.256500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.253300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.249400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.247300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.244200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.242000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.240500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.238300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.236500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.235300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.233500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.232200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.231000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.229800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.228700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.228500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.227500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.226100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.225700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.224900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.224400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.223400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.222900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.222400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.221700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.221600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.220600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.220700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.219900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.219800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.218800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.218700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.218500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.218100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>0.217600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.217900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>0.217200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.216600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>0.216500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.216300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.216200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.216100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>0.215900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.216200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>0.215800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.215400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>0.215100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.215200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>0.215100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.214600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>0.215100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.214600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1069it [00:26, 40.60it/s]                                                                                                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "Data Dropped: 98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192it [00:04, 40.28it/s]                                                                                                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n",
      "Data Dropped: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "97it [00:02, 39.14it/s]                                                                                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Data Dropped: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99it [00:02, 42.74it/s]                                                                                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Data Dropped: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sharedrive/Nasik/LLM_3.9/lib/python3.9/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 01:21, Epoch 1000/1000]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.322800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.182400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1059it [00:27, 38.23it/s]                                                                                                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "Data Dropped: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "97it [00:02, 38.99it/s]                                                                                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "Data Dropped: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sharedrive/Nasik/LLM_3.9/lib/python3.9/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 03:32, Epoch 1000/1000]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.364000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.200900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1054it [00:28, 37.05it/s]                                                                                                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "Data Dropped: 142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192it [00:04, 40.20it/s]                                                                                                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n",
      "Data Dropped: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94it [00:02, 39.06it/s]                                                                                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "Data Dropped: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99it [00:02, 41.79it/s]                                                                                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Data Dropped: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "97it [00:02, 40.34it/s]                                                                                                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Data Dropped: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sharedrive/Nasik/LLM_3.9/lib/python3.9/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43000' max='43000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43000/43000 3:08:09, Epoch 1000/1000]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.711600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.589700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.535700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.478100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.424200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.385300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.359000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.341100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.327100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.315800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.306300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.298000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.291000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.284600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.278500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.273500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.269300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.265300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.261700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.258500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.256200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.254000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.251600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.249000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.247500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.246000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.244500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.243000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.241700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.240500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.239100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.238400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.237200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.236700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.236100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.235100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.234000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.233300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.232600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.232000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.231600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.230900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.230200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.229700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.229500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.228600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.228200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.228000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>0.227200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.227100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>0.226900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.226300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>0.226300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.225400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.225100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.225200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>0.224500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.224400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>0.224200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>0.223600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.223000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>0.223100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.222800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>0.222500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.222100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>0.222100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.222100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>0.221500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.221400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>0.221300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.221100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36500</td>\n",
       "      <td>0.221100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>0.220900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37500</td>\n",
       "      <td>0.221000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.220800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38500</td>\n",
       "      <td>0.220300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>0.220400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39500</td>\n",
       "      <td>0.220300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.220200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40500</td>\n",
       "      <td>0.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>0.220200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41500</td>\n",
       "      <td>0.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42500</td>\n",
       "      <td>0.219700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>0.219900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1081it [00:25, 41.90it/s]                                                                                                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "Data Dropped: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99it [00:02, 42.27it/s]                                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Data Dropped: 0\n",
      "Synthetic data has been saved to 'synthetic_data.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sdv.single_table import CTGANSynthesizer, TVAESynthesizer\n",
    "#from sdv.tabular import CTGAN\n",
    "from sdv.metadata import Metadata\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "from collections import defaultdict\n",
    "#import pdb;pdb.set_trace()\n",
    "\n",
    "from be_great import GReaT\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# Disable tokenizer parallelism warning\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 4200\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "#use this onee\n",
    "rf_features = ['Flow_Duration', 'Total_Length_of_Bwd_Packets', 'Bwd_Packet_Length_Max',\n",
    "       'Bwd_Packet_Length_Mean', 'Flow_Bytes/s', 'Flow_Packets/s',\n",
    "       'Flow_IAT_Mean', 'Flow_IAT_Std', 'Flow_IAT_Max',\n",
    "       'Fwd_IAT_Total', 'Fwd_IAT_Mean', 'Fwd_IAT_Std', 'Fwd_IAT_Max',\n",
    "       'Fwd_IAT_Min', 'Fwd_Packets/s', 'Bwd_Packets/s', 'Max_Packet_Length',\n",
    "       'Packet_Length_Mean', 'Average_Packet_Size', 'Avg_Bwd_Segment_Size',\n",
    "       'Subflow_Bwd_Bytes', 'min_seg_size_forward']\n",
    "\n",
    "real_data = pd.read_csv(\"./Data/CICIDS_data/CICIDS_clean_train.csv\")\n",
    "\n",
    "\n",
    "def change(df):\n",
    "    column_names = list(df.columns)\n",
    "    new_column_names = [name.strip().replace(\" \", \"_\") for name in column_names]\n",
    "    _dict = {k:v for k,v in zip(column_names, new_column_names)}\n",
    "    df.rename(columns = _dict, inplace = True)\n",
    "    labels = df[\"Label\"].unique().tolist()\n",
    "    new_labels = [''.join(filter(lambda x: ord(x)<128, l.strip().replace(\" \",\"_\"))) for l in labels]\n",
    "    _dict = {k:v for k,v in zip(labels, new_labels)}\n",
    "    df[\"Label\"].replace(to_replace=_dict, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "real_data = change(real_data)\n",
    "\n",
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    for column in df.select_dtypes(include=[np.number]).columns:\n",
    "        mean_value = df[df[column] >= 0][column].mean()\n",
    "        df[column] = df[column].apply(lambda x: mean_value if x < 0 else x)\n",
    "    df = df.loc[:, (df != 0).any(axis=0)]\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(axis=1)\n",
    "    return df[indices_to_keep]\n",
    "\n",
    "filtered_data = clean_dataset(real_data[rf_features+['Label']])\n",
    "\n",
    "#real_data = clean_dataset(real_data)\n",
    "#real_data = real_data[rf_features]\n",
    "\n",
    "\n",
    "\n",
    "with open(\"./DT_KB_CIC_2.json\", \"r\") as file:\n",
    "    rules = json.load(file)\n",
    "\n",
    "\n",
    "def clean_kb(kb):\n",
    "    up_kb = {}\n",
    "    for cls in kb.keys():\n",
    "        ld_rl = kb[cls]\n",
    "        print(f\"Before: {len(ld_rl)}\")\n",
    "        result = []\n",
    "        for item in ld_rl:\n",
    "            if item not in result:  # Directly check for duplicates\n",
    "                result.append(item)\n",
    "            #else:\n",
    "            #    print(item)\n",
    "        print(f\"After: {len(result)}\")\n",
    "        up_kb[cls] = result\n",
    "    return up_kb\n",
    "\n",
    "rules = clean_kb(rules)\n",
    "\n",
    "\n",
    "def process_data(x, cls):\n",
    "    global rules\n",
    "    kb = rules[cls]\n",
    "\n",
    "    indices_to_remove = []\n",
    "    for i,row in x.iterrows():\n",
    "        isTrue = 0\n",
    "        for path in kb:\n",
    "            flag = 0\n",
    "            for f,r,t in path:\n",
    "                if r == '>' and not (row.iloc[f]>t):\n",
    "                    flag = 1\n",
    "                    break\n",
    "                elif r == '<=' and not (row.iloc[f]<=t):\n",
    "                    flag = 1\n",
    "                    break\n",
    "            if flag == 0:\n",
    "                isTrue = 1\n",
    "                break\n",
    "        if isTrue==0:\n",
    "            indices_to_remove.append(i)\n",
    "    print(f\"Data Dropped: {len(indices_to_remove)}\")\n",
    "    t_x = x.drop(indices_to_remove).reset_index(drop=True)\n",
    "    return t_x\n",
    "\n",
    "selected_classes = [\"Web_Attack__Sql_Injection\",\"Web_Attack__XSS\", \"Web_Attack__Brute_Force\", \"Heartbleed\", \"Infiltration\", \"Bot\"]\n",
    "\n",
    "#selected_classes = [ \"Heartbleed\"]\n",
    "\n",
    "#model = GReaT(llm='distilgpt2', batch_size=32, epochs=1000, fp16=True, seed=SEED)\n",
    "#model = GReaT(llm='distilgpt2', batch_size=32, epochs=500, fp16=True, seed=SEED, **{save_total_limit=2,load_best_model_at_end=True})\n",
    "model = GReaT(\n",
    "    llm='distilgpt2',\n",
    "    batch_size=32,\n",
    "    epochs=1000,\n",
    "    fp16=True,\n",
    "    seed=SEED,\n",
    "    save_total_limit=5,  # Limit the number of checkpoints\n",
    "    #load_best_model_at_end=True,  # Load the best model at the end of training\n",
    "    #eval_strategy ='steps',\n",
    "    #eval_dataset = ''\n",
    ")\n",
    "\n",
    "target = 1000\n",
    "synthetic_data_all = pd.DataFrame()\n",
    "\n",
    "for label in selected_classes:\n",
    "    class_data = filtered_data[filtered_data['Label'] == label]\n",
    "\n",
    "    model.fit(class_data)\n",
    "    \n",
    "\n",
    "    synthetic_class_data = []\n",
    "    sampled_data_len = 0\n",
    "\n",
    "    \n",
    "    while sampled_data_len < target:\n",
    "            \n",
    "        sampled = model.sample(n_samples=target-sampled_data_len, max_length=2000)\n",
    "\n",
    "        print(len(sampled))\n",
    "        cons_sampled = process_data(sampled, label)\n",
    "\n",
    "  \n",
    "        sampled_data_len += len(cons_sampled)\n",
    "        synthetic_class_data.append(cons_sampled)\n",
    "            \n",
    "    syn_data = pd.concat(synthetic_class_data, ignore_index=True)\n",
    "    \n",
    "    syn_data['Label'] = label\n",
    "    synthetic_data_all = pd.concat([synthetic_data_all, syn_data], ignore_index=True)\n",
    "\n",
    "# Save the synthetic data to a CSV file\n",
    "synthetic_data_all.to_csv(\"./Data/CICIDS_data/Great_Synthetic_1000_R1_N.csv\", index=False)\n",
    "print(\"Synthetic data has been saved to 'synthetic_data.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a0e59d9-e965-4739-bd96-e8461d9e1e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow_Duration</th>\n",
       "      <th>Total_Length_of_Bwd_Packets</th>\n",
       "      <th>Bwd_Packet_Length_Max</th>\n",
       "      <th>Bwd_Packet_Length_Mean</th>\n",
       "      <th>Flow_Bytes/s</th>\n",
       "      <th>Flow_Packets/s</th>\n",
       "      <th>Flow_IAT_Mean</th>\n",
       "      <th>Flow_IAT_Std</th>\n",
       "      <th>Flow_IAT_Max</th>\n",
       "      <th>Fwd_IAT_Total</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd_IAT_Min</th>\n",
       "      <th>Fwd_Packets/s</th>\n",
       "      <th>Bwd_Packets/s</th>\n",
       "      <th>Max_Packet_Length</th>\n",
       "      <th>Packet_Length_Mean</th>\n",
       "      <th>Average_Packet_Size</th>\n",
       "      <th>Avg_Bwd_Segment_Size</th>\n",
       "      <th>Subflow_Bwd_Bytes</th>\n",
       "      <th>min_seg_size_forward</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46511.627910</td>\n",
       "      <td>43.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23255.813950</td>\n",
       "      <td>23255.813950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Web_Attack__Sql_Injection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28169.014080</td>\n",
       "      <td>71.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14084.507040</td>\n",
       "      <td>14084.507040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Web_Attack__Sql_Injection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5005388.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>673.666667</td>\n",
       "      <td>523.435945</td>\n",
       "      <td>1.598278</td>\n",
       "      <td>715055.4286</td>\n",
       "      <td>1.889529e+04</td>\n",
       "      <td>5000145.0</td>\n",
       "      <td>6119.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.799014</td>\n",
       "      <td>0.799014</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>291.111111</td>\n",
       "      <td>327.500000</td>\n",
       "      <td>673.666667</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Web_Attack__Sql_Injection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5005168.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>673.666667</td>\n",
       "      <td>933.644955</td>\n",
       "      <td>1.597616</td>\n",
       "      <td>715055.4286</td>\n",
       "      <td>1.765197e+06</td>\n",
       "      <td>5000160.0</td>\n",
       "      <td>52746.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.798455</td>\n",
       "      <td>0.798455</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>291.111111</td>\n",
       "      <td>327.500000</td>\n",
       "      <td>673.666667</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Web_Attack__Sql_Injection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5012479.0</td>\n",
       "      <td>4149.0</td>\n",
       "      <td>2701.0</td>\n",
       "      <td>1037.250000</td>\n",
       "      <td>933.644955</td>\n",
       "      <td>1.995021</td>\n",
       "      <td>556942.1111</td>\n",
       "      <td>1.666210e+06</td>\n",
       "      <td>5000160.0</td>\n",
       "      <td>5012479.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.197012</td>\n",
       "      <td>0.798008</td>\n",
       "      <td>2701.0</td>\n",
       "      <td>431.727273</td>\n",
       "      <td>474.900000</td>\n",
       "      <td>1037.250000</td>\n",
       "      <td>4149.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Web_Attack__Sql_Injection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>83.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>144578.313300</td>\n",
       "      <td>24096.385540</td>\n",
       "      <td>83.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12048.192770</td>\n",
       "      <td>12048.192770</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>50.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>240000.000000</td>\n",
       "      <td>40000.000000</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>69188.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>44.666667</td>\n",
       "      <td>4958.030705</td>\n",
       "      <td>101.298062</td>\n",
       "      <td>11586.0000</td>\n",
       "      <td>2.713479e+04</td>\n",
       "      <td>67223.0</td>\n",
       "      <td>69188.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>57.540710</td>\n",
       "      <td>43.516101</td>\n",
       "      <td>194.0</td>\n",
       "      <td>42.500000</td>\n",
       "      <td>48.571429</td>\n",
       "      <td>44.666667</td>\n",
       "      <td>134.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>600000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Bot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>1029486.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>17.484453</td>\n",
       "      <td>5.828151</td>\n",
       "      <td>205897.2000</td>\n",
       "      <td>2.810339e+05</td>\n",
       "      <td>515138.0</td>\n",
       "      <td>1028980.0</td>\n",
       "      <td>...</td>\n",
       "      <td>515642.0</td>\n",
       "      <td>2.914076</td>\n",
       "      <td>2.914076</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Bot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Flow_Duration  Total_Length_of_Bwd_Packets  Bwd_Packet_Length_Max  \\\n",
       "0              43.0                          0.0                    0.0   \n",
       "1              71.0                          0.0                    0.0   \n",
       "2         5005388.0                       2021.0                 2021.0   \n",
       "3         5005168.0                       2021.0                 2021.0   \n",
       "4         5012479.0                       4149.0                 2701.0   \n",
       "...             ...                          ...                    ...   \n",
       "5995           83.0                          6.0                    6.0   \n",
       "5996           50.0                          6.0                    6.0   \n",
       "5997        69188.0                        134.0                  128.0   \n",
       "5998           20.0                          6.0                    6.0   \n",
       "5999      1029486.0                         18.0                    6.0   \n",
       "\n",
       "      Bwd_Packet_Length_Mean   Flow_Bytes/s  Flow_Packets/s  Flow_IAT_Mean  \\\n",
       "0                   0.000000       0.000000    46511.627910        43.0000   \n",
       "1                   0.000000       0.000000    28169.014080        71.0000   \n",
       "2                 673.666667     523.435945        1.598278    715055.4286   \n",
       "3                 673.666667     933.644955        1.597616    715055.4286   \n",
       "4                1037.250000     933.644955        1.995021    556942.1111   \n",
       "...                      ...            ...             ...            ...   \n",
       "5995                6.000000  144578.313300    24096.385540        83.0000   \n",
       "5996                6.000000  240000.000000    40000.000000        50.0000   \n",
       "5997               44.666667    4958.030705      101.298062     11586.0000   \n",
       "5998                6.000000  600000.000000   100000.000000        20.0000   \n",
       "5999                6.000000      17.484453        5.828151    205897.2000   \n",
       "\n",
       "      Flow_IAT_Std  Flow_IAT_Max  Fwd_IAT_Total  ...  Fwd_IAT_Min  \\\n",
       "0     0.000000e+00          43.0            0.0  ...          0.0   \n",
       "1     0.000000e+00          71.0            0.0  ...          0.0   \n",
       "2     1.889529e+04     5000145.0         6119.0  ...          4.0   \n",
       "3     1.765197e+06     5000160.0        52746.0  ...          4.0   \n",
       "4     1.666210e+06     5000160.0      5012479.0  ...          3.0   \n",
       "...            ...           ...            ...  ...          ...   \n",
       "5995  0.000000e+00          83.0            0.0  ...          0.0   \n",
       "5996  0.000000e+00          50.0            0.0  ...          0.0   \n",
       "5997  2.713479e+04       67223.0        69188.0  ...         25.0   \n",
       "5998  0.000000e+00          20.0            0.0  ...          0.0   \n",
       "5999  2.810339e+05      515138.0      1028980.0  ...     515642.0   \n",
       "\n",
       "      Fwd_Packets/s  Bwd_Packets/s  Max_Packet_Length  Packet_Length_Mean  \\\n",
       "0      23255.813950   23255.813950                0.0            0.000000   \n",
       "1      14084.507040   14084.507040                0.0            0.000000   \n",
       "2          0.799014       0.799014             2021.0          291.111111   \n",
       "3          0.798455       0.798455             2021.0          291.111111   \n",
       "4          1.197012       0.798008             2701.0          431.727273   \n",
       "...             ...            ...                ...                 ...   \n",
       "5995   12048.192770   12048.192770                6.0            6.000000   \n",
       "5996   20000.000000   20000.000000                6.0            6.000000   \n",
       "5997      57.540710      43.516101              194.0           42.500000   \n",
       "5998   50000.000000   50000.000000                6.0            6.000000   \n",
       "5999       2.914076       2.914076                6.0            2.571429   \n",
       "\n",
       "      Average_Packet_Size  Avg_Bwd_Segment_Size  Subflow_Bwd_Bytes  \\\n",
       "0                0.000000              0.000000                0.0   \n",
       "1                0.000000              0.000000                0.0   \n",
       "2              327.500000            673.666667             2021.0   \n",
       "3              327.500000            673.666667             2021.0   \n",
       "4              474.900000           1037.250000             4149.0   \n",
       "...                   ...                   ...                ...   \n",
       "5995             9.000000              6.000000                6.0   \n",
       "5996             9.000000              6.000000                6.0   \n",
       "5997            48.571429             44.666667              134.0   \n",
       "5998             9.000000              6.000000                6.0   \n",
       "5999             3.000000              6.000000               18.0   \n",
       "\n",
       "      min_seg_size_forward                      Label  \n",
       "0                     32.0  Web_Attack__Sql_Injection  \n",
       "1                     32.0  Web_Attack__Sql_Injection  \n",
       "2                     32.0  Web_Attack__Sql_Injection  \n",
       "3                     32.0  Web_Attack__Sql_Injection  \n",
       "4                     32.0  Web_Attack__Sql_Injection  \n",
       "...                    ...                        ...  \n",
       "5995                  20.0                        Bot  \n",
       "5996                  20.0                        Bot  \n",
       "5997                  20.0                        Bot  \n",
       "5998                  20.0                        Bot  \n",
       "5999                  28.0                        Bot  \n",
       "\n",
       "[6000 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033ea6a2-f347-4321-9b00-b279d62f8b31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3394b986-eadf-4993-9289-c69690e1efcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM 3.9",
   "language": "python",
   "name": "llm_3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
